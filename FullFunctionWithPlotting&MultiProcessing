import os
import time
import subprocess
import smtplib
from email.message import EmailMessage
import logging
import sys
import psutil
import numpy as np
from collections import defaultdict
import multiprocessing
import time
import matplotlib.pyplot as plt
import pandas as pd

def monitoring_code(stop_time, shared_dict):
  config = {
    "z_score_threshold": 3.0,  # Default threshold for Z-scores
    "metrics": ["mem_usage", "temp", "power_draw"]  # Metrics to monitor
}
# Constants
MONITORING_INTERVAL = int(os.environ.get('MONITORING_INTERVAL', 60))
THRESHOLD = float(os.environ.get('THRESHOLD', 0.8))
SMTP_SERVER = os.environ.get('SMTP_SERVER', '')
SMTP_PORT = int(os.environ.get('SMTP_PORT', 587))
EMAIL_ADDRESS = os.environ.get('EMAIL_ADDRESS', '')
EMAIL_PASSWORD = os.environ.get('EMAIL_PASSWORD', '')
TO_EMAILS = list(map(str.strip, os.environ.get('TO_EMAILS', '').split(',')))
LOG_FILE = 'gpu_monitor.log'

def send_email(subject, body):
    msg = EmailMessage()
    msg.set_content(body)
    msg['Subject'] = subject
    msg['From'] = EMAIL_ADDRESS
    msg['To'] = TO_EMAILS[0]

    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)
    server.starttls()
    server.login(EMAIL_ADDRESS, EMAIL_PASSWORD)
    server.send_message(msg)
    server.quit()

def check_anomaly(current_stats, prev_stats, config):
    anomalies = []
    for idx, stat in current_stats.items():
        for metric in config["metrics"]:
            try:
                # Calculate Z-score based on previous values
                history = np.array([val[metric] for val in prev_stats.values()])  # Extract metric history
                mean = history.mean()
                std = history.std()
                if std > 0:  # Avoid division by zero
                    z_score = (stat[metric] - mean) / std
                    if np.abs(z_score) > config["z_score_threshold"]:  # Add threshold for z-scores
                        anomalies.append((idx, f"{metric} (Z-score: {z_score:.2f})"))
            except (ValueError, ZeroDivisionError) as e:
                logging.warning(f"Error calculating Z-score for metric {metric}: {str(e)}")
    return anomalies

import csv

def gather_gpu_stats(file_name='gpu_stats.csv'):
    """
    Gather GPU stats using platform-dependent commands, with enhanced error handling.

    Save the collected data into a file in CSV format.
    """
    config = {
        "z_score_threshold": 3.0  # Default threshold for Z-scores
    }

    try:
        process = psutil.Process(os.getpid())
        device_memory = process.memory_info().vms / 1e9

        if GPU_VENDOR == "NVIDIA":
            cmd = ["nvidia-smi", "--format=csv", "--query-gpu=index,memory.used,temperature.gpu,power.draw"]
        elif GPU_VENDOR == "AMD":
            cmd = ["rocminfo", "-f", "csv", "--power", "state"]  # Add more metrics if available
        else:
            raise ValueError("Unsupported GPU vendor")

        result = subprocess.check_output(cmd, universal_newlines=True)
    except Exception as e:
        logging.error(f"Error fetching GPU stats: {str(e)}")
        return {}

    # Parse output and extract relevant metrics
    gpu_data = dict()
    lines = result.strip().split("\n")
    header = lines.pop(0).split(',')
    with open(file_name, mode='a') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=header)
        if len(lines) == 0:
            writer.writeheader()
        for line in lines:
            parts = line.split(',')
            index = int(parts[0].replace(" ", ""))
            mem_usage = float(parts[1].replace("MiB", "").replace(" ", "")) / 1024**2
            temp = float(parts[2].replace(" C", ""))
            power_draw = float(parts[3].replace("W", ""))
            gpu_data[index] = {'mem_usage': mem_usage, 'temp': temp, 'power_draw': power_draw}
            writer = csv.DictWriter(csvfile, fieldnames=['index', 'mem_usage', 'temp', 'power_draw'])  # Add missing fields

    return gpu_data

def main():
    global GPU_VENDOR

    try:
        GPU_VENDOR = psutil.cpu_info().manufacturer
    except AttributeError:
        GPU_VENDOR = 'NVIDIA'

    prev_stats = defaultdict(float)

    logging.basicConfig(filename=LOG_FILE, level=logging.INFO)  # Set up logging

    # Create a Manager object to control the shared data
    manager = multiprocessing.Manager()
    shared_dict = manager.dict()

    # Create a Value to share the stop time
    stop_time = multiprocessing.Value('d', time.time() + 60 * 2)  # Replace X with the number of minutes

    while True:
        try:
            current_stats = gather_gpu_stats()

            # Update shared_dict with the collected stats
            for idx, stats in current_stats.items():
                shared_dict[idx] = stats

            anomalies = check_anomaly(current_stats, prev_stats, config)
            if anomalies:
                subject = f"GPU Memory Anomaly Detected (Threshold={THRESHOLD})"
                bodies = [f"Anomalous GPU #{idx}: {metric}" for idx, metric in anomalies]
                body = "\n".join(bodies)
                send_email(subject, body)
                print(f"{time.ctime()} - Sent email:\nSubject: {subject}\nBody: {body}")

            prev_stats = current_stats

            # Check if the current time has exceeded the stop time
            if time.time() > stop_time.value:
                break

        except KeyboardInterrupt:
            break

        finally:
            time.sleep(MONITORING_INTERVAL)

def plotting_code(shared_dict):
    # Load the data from shared_dict
    data = list(shared_dict.values())
    df_gpu = pd.DataFrame(data)

    # Create a line plot of GPU usage over time
    plt.figure(figsize=(10, 6))
    plt.plot(df_gpu['timestamp'], df_gpu['usage_gpu'], label='GPU Usage (%)')
    plt.xlabel('Timestamp')
    plt.ylabel('Usage (%)')
    plt.title('GPU Usage Over Time')
    plt.legend(loc='best')
    plt.grid(True)
    plt.show()

    # Create processes
    p1 = multiprocessing.Process(target=monitoring_code, args=(stop_time, shared_dict))
    p2 = multiprocessing.Process(target=plotting_code, args=(shared_dict,))

    # Start processes
    p1.start()
    p2.start()

    # Join processes
    p1.join()
    p2.join()

if __name__ == "__main__":
    main()
